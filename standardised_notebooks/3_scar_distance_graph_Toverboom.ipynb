{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'toverboom'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-29c8d53a33b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtoverboom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtoverboom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizeLayout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtoverboom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineageGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'toverboom'"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import collections\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "\n",
    "from networkx.drawing.nx_agraph import write_dot, graphviz_layout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import toverboom\n",
    "import toverboom.optimizeLayout\n",
    "import toverboom.lineageGraph\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import scar data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToData = '/Users/m.blotenburg/Documents/Projects/Mouse_Scartrace/Data_analysis/Scar_analysis/20200414_VAN2988_remap_BWAfilters_AlleleCalling_maskedGenome/'\n",
    "df = pd.read_pickle(pathToData + '120hAA_dataframeForHeatmap_All.pickle.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import transcriptome data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_clusters = pd.read_csv('/Users/m.blotenburg/Desktop/scanpy_cells_louvainclusters_colors120hAA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cellname</th>\n",
       "      <th>index</th>\n",
       "      <th>louvain</th>\n",
       "      <th>umap_V1</th>\n",
       "      <th>umap_V2</th>\n",
       "      <th>cellname.1</th>\n",
       "      <th>gastruloid</th>\n",
       "      <th>louvain_colors</th>\n",
       "      <th>germlayer_colors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1_1</td>\n",
       "      <td>A1_1.C5A4</td>\n",
       "      <td>Early endoderm1</td>\n",
       "      <td>0.168446</td>\n",
       "      <td>-3.569604</td>\n",
       "      <td>A1_1</td>\n",
       "      <td>C5A4</td>\n",
       "      <td>orange</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1_10</td>\n",
       "      <td>A1_10.C5C3</td>\n",
       "      <td>Early endoderm1</td>\n",
       "      <td>1.129176</td>\n",
       "      <td>-4.579352</td>\n",
       "      <td>A1_10</td>\n",
       "      <td>C5C3</td>\n",
       "      <td>orange</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1_100</td>\n",
       "      <td>A1_100.C5C3</td>\n",
       "      <td>Early endoderm2</td>\n",
       "      <td>4.106470</td>\n",
       "      <td>-4.697111</td>\n",
       "      <td>A1_100</td>\n",
       "      <td>C5C3</td>\n",
       "      <td>orange</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1_102</td>\n",
       "      <td>A1_102.C5C3</td>\n",
       "      <td>Neurons1</td>\n",
       "      <td>-0.229431</td>\n",
       "      <td>3.547628</td>\n",
       "      <td>A1_102</td>\n",
       "      <td>C5C3</td>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1_103</td>\n",
       "      <td>A1_103.C5C3</td>\n",
       "      <td>Early endoderm2</td>\n",
       "      <td>2.677049</td>\n",
       "      <td>-3.243759</td>\n",
       "      <td>A1_103</td>\n",
       "      <td>C5C3</td>\n",
       "      <td>orange</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cellname        index          louvain   umap_V1   umap_V2 cellname.1  \\\n",
       "0     A1_1    A1_1.C5A4  Early endoderm1  0.168446 -3.569604       A1_1   \n",
       "1    A1_10   A1_10.C5C3  Early endoderm1  1.129176 -4.579352      A1_10   \n",
       "2   A1_100  A1_100.C5C3  Early endoderm2  4.106470 -4.697111     A1_100   \n",
       "3   A1_102  A1_102.C5C3         Neurons1 -0.229431  3.547628     A1_102   \n",
       "4   A1_103  A1_103.C5C3  Early endoderm2  2.677049 -3.243759     A1_103   \n",
       "\n",
       "  gastruloid louvain_colors germlayer_colors  \n",
       "0       C5A4         orange             blue  \n",
       "1       C5C3         orange             blue  \n",
       "2       C5C3         orange             blue  \n",
       "3       C5C3          green            green  \n",
       "4       C5C3         orange             blue  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cells_clusters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define pre-scarred regions, definitions for graph construction, tree building, and tree visualisation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the most common scars for a certain allele/site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mostCommonScars = {scar:collections.Counter(df[scar]).most_common(1) for scar in df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129, 114682729</th>\n",
       "      <td>(WT, 1442)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129, 114708745</th>\n",
       "      <td>(WT, 269)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129, 114723869</th>\n",
       "      <td>(WT, 57)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129, 114788469</th>\n",
       "      <td>(114788523.D,114788524.D,114788525.D,114788526...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129, 114817194</th>\n",
       "      <td>(WT, 2632)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129, 114875401</th>\n",
       "      <td>(WT, 377)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129, 114879985</th>\n",
       "      <td>(WT, 595)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129, 114896335</th>\n",
       "      <td>(WT, 215)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129, 114781506</th>\n",
       "      <td>(WT, 58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129, 114896366</th>\n",
       "      <td>(nan, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                0\n",
       "129, 114682729                                         (WT, 1442)\n",
       "129, 114708745                                          (WT, 269)\n",
       "129, 114723869                                           (WT, 57)\n",
       "129, 114788469  (114788523.D,114788524.D,114788525.D,114788526...\n",
       "129, 114817194                                         (WT, 2632)\n",
       "129, 114875401                                          (WT, 377)\n",
       "129, 114879985                                          (WT, 595)\n",
       "129, 114896335                                          (WT, 215)\n",
       "129, 114781506                                           (WT, 58)\n",
       "129, 114896366                                           (nan, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostCommonScarsdf = pd.DataFrame(mostCommonScars).T\n",
    "mostCommonScarsdf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all alleleSites where the same scar has been counted >20 times to check for pre-scarred sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129, 114788469 ('114788523.D,114788524.D,114788525.D,114788526.D,114788527.D', 2242)\n",
      "B6, 114740505 ('114740560.D', 1879)\n",
      "B6, 114788469 ('114788523.D,114788524.D,114788525.D,114788526.D,114788527.D', 2526)\n",
      "B6, 114914696 ('114914747.D,114914748.D,114914749.D,114914750.D,114914751.D,114914752.D,114914753.D,114914754.D,114914755.D', 202)\n",
      "nonallelic, 114682729 ('114682770.D,114682771.D,114682772.D,114682773.D,114682774.D,114682775.D,114682776.D,114682777.D,114682778.D,114682779.D,114682780.D,114682781.D,114682782.D,114682783.D,114682784.D,114682785.D,114682786.D,114682787.D,114682788.D', 1052)\n",
      "nonallelic, 114740505 ('114740560.D', 38)\n",
      "nonallelic, 114788469 ('114788523.D,114788524.D,114788525.D,114788526.D,114788527.D', 890)\n",
      "nonallelic, 116009756 ('116009771.D,116009772.D', 122)\n"
     ]
    }
   ],
   "source": [
    "for x in mostCommonScarsdf.items():\n",
    "    for (site,count) in x[1].items():\n",
    "        if count[0] != 'WT' and count[1] > 20:\n",
    "            print(site,count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a pre-scarred pattern for the gastruloids that are pre-scarred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pre-scar pattern:\n",
    "pre_scar_pattern = {  \n",
    "    #'129, 114788469': '114788523.D,114788524.D,114788525.D,114788526.D,114788527.D',\n",
    "    'B6, 114788469': '114788523.D,114788524.D,114788525.D,114788526.D,114788527.D',\n",
    "    'B6, 114740505': '114740560.D'\n",
    "   # 'B6, 114746370':'114746424.D,114746425.D,114746426.D,114746427.D,114746428.D', \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to select which sites to use. We know where the gRNA target sites are located, this is our selection. We then need to filter out the sites with too little coverage. For now we also do not use nonallelic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USE SCAR TARGET SITES ONLY\n",
    "# select scar target sites:\n",
    "selectionAll = df[['129, 114682729', 'B6, 114682729', #'nonallelic, 114682729',\n",
    "                          '129, 114708745', 'B6, 114708745', #'nonallelic, 114708745',\n",
    "                          '129, 114723869', 'B6, 114723869', #'nonallelic, 114723869',\n",
    "                          #'129, 114736342', #'nonallelic, 114736342',\n",
    "                         # '129, 114740505',\n",
    "                           'B6, 114740505', #'nonallelic, 114740505',\n",
    "                          #'129, 114746369', #'B6, 114746369', 'nonallelic, 114746370',\n",
    "                          '129, 114788469', 'B6, 114788469', #'nonallelic, 114788469',\n",
    "                          #'129, 114843748', \n",
    "                   #'B6, 114843748', 'nonallelic, 114843748',\n",
    "                          'B6, 114851287', #'nonallelic, 114851287',\n",
    "                          '129, 114879985', #'B6, 114879985', #'nonallelic, 114879985',\n",
    "                          '129, 114896335', #'nonallelic, 114896335',\n",
    "                         #'129, 114910169', #'B6, 114910169', 'nonallelic, 114910169',\n",
    "                        # '129, 114914696', \n",
    "                   'B6, 114914696']] #'nonallelic, 114914696']]\n",
    "\n",
    "#selection = selection.loc['C5F10']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>129, 114682729</th>\n",
       "      <th>B6, 114682729</th>\n",
       "      <th>129, 114708745</th>\n",
       "      <th>B6, 114708745</th>\n",
       "      <th>129, 114723869</th>\n",
       "      <th>B6, 114723869</th>\n",
       "      <th>B6, 114740505</th>\n",
       "      <th>129, 114788469</th>\n",
       "      <th>B6, 114788469</th>\n",
       "      <th>B6, 114851287</th>\n",
       "      <th>129, 114879985</th>\n",
       "      <th>129, 114896335</th>\n",
       "      <th>B6, 114914696</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">C5A9</th>\n",
       "      <th>A2_1</th>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>114740560.D</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2_10</th>\n",
       "      <td>WT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WT</td>\n",
       "      <td>114740560.D</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2_100</th>\n",
       "      <td>WT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2_101</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WT</td>\n",
       "      <td>114740560.D</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114914747.D,114914748.D,114914749.D,114914750....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2_102</th>\n",
       "      <td>114682783.D,114682784.D,114682785.D,114682786....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114740560.D</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">C5H9</th>\n",
       "      <th>E2_95</th>\n",
       "      <td>114682778.D,114682779.D,114682780.D,114682781....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114723925.D,114723926.D,114723927.D,114723928....</td>\n",
       "      <td>114740560.D</td>\n",
       "      <td>WT</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E2_96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114740560.D</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E2_97</th>\n",
       "      <td>G.114682786.I,G.114682787.I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114723923.D,114723924.D,114723925.D,114723926....</td>\n",
       "      <td>114740560.D</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E2_98</th>\n",
       "      <td>114682783.D,114682784.D,114682785.D,114682786....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WT</td>\n",
       "      <td>114740560.D</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114914747.D,114914748.D,114914749.D,114914750....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E2_99</th>\n",
       "      <td>WT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WT</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2997 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                129, 114682729 B6, 114682729  \\\n",
       "C5A9 A2_1                                                   WT            WT   \n",
       "     A2_10                                                  WT           NaN   \n",
       "     A2_100                                                 WT           NaN   \n",
       "     A2_101                                                NaN           NaN   \n",
       "     A2_102  114682783.D,114682784.D,114682785.D,114682786....           NaN   \n",
       "...                                                        ...           ...   \n",
       "C5H9 E2_95   114682778.D,114682779.D,114682780.D,114682781....           NaN   \n",
       "     E2_96                                                 NaN           NaN   \n",
       "     E2_97                         G.114682786.I,G.114682787.I           NaN   \n",
       "     E2_98   114682783.D,114682784.D,114682785.D,114682786....           NaN   \n",
       "     E2_99                                                  WT           NaN   \n",
       "\n",
       "            129, 114708745 B6, 114708745 129, 114723869  \\\n",
       "C5A9 A2_1               WT            WT             WT   \n",
       "     A2_10             NaN           NaN            NaN   \n",
       "     A2_100            NaN           NaN            NaN   \n",
       "     A2_101            NaN           NaN            NaN   \n",
       "     A2_102            NaN           NaN            NaN   \n",
       "...                    ...           ...            ...   \n",
       "C5H9 E2_95             NaN           NaN            NaN   \n",
       "     E2_96              WT           NaN            NaN   \n",
       "     E2_97             NaN           NaN            NaN   \n",
       "     E2_98             NaN           NaN            NaN   \n",
       "     E2_99             NaN           NaN            NaN   \n",
       "\n",
       "                                                 B6, 114723869 B6, 114740505  \\\n",
       "C5A9 A2_1                                                   WT   114740560.D   \n",
       "     A2_10                                                  WT   114740560.D   \n",
       "     A2_100                                                 WT           NaN   \n",
       "     A2_101                                                 WT   114740560.D   \n",
       "     A2_102                                                NaN   114740560.D   \n",
       "...                                                        ...           ...   \n",
       "C5H9 E2_95   114723925.D,114723926.D,114723927.D,114723928....   114740560.D   \n",
       "     E2_96                                                 NaN   114740560.D   \n",
       "     E2_97   114723923.D,114723924.D,114723925.D,114723926....   114740560.D   \n",
       "     E2_98                                                  WT   114740560.D   \n",
       "     E2_99                                                 NaN           NaN   \n",
       "\n",
       "                                                129, 114788469  \\\n",
       "C5A9 A2_1    114788523.D,114788524.D,114788525.D,114788526....   \n",
       "     A2_10   114788523.D,114788524.D,114788525.D,114788526....   \n",
       "     A2_100  114788523.D,114788524.D,114788525.D,114788526....   \n",
       "     A2_101  114788523.D,114788524.D,114788525.D,114788526....   \n",
       "     A2_102  114788523.D,114788524.D,114788525.D,114788526....   \n",
       "...                                                        ...   \n",
       "C5H9 E2_95                                                  WT   \n",
       "     E2_96   114788523.D,114788524.D,114788525.D,114788526....   \n",
       "     E2_97   114788523.D,114788524.D,114788525.D,114788526....   \n",
       "     E2_98   114788523.D,114788524.D,114788525.D,114788526....   \n",
       "     E2_99                                                  WT   \n",
       "\n",
       "                                                 B6, 114788469 B6, 114851287  \\\n",
       "C5A9 A2_1    114788523.D,114788524.D,114788525.D,114788526....           NaN   \n",
       "     A2_10   114788523.D,114788524.D,114788525.D,114788526....           NaN   \n",
       "     A2_100  114788523.D,114788524.D,114788525.D,114788526....           NaN   \n",
       "     A2_101  114788523.D,114788524.D,114788525.D,114788526....           NaN   \n",
       "     A2_102  114788523.D,114788524.D,114788525.D,114788526....           NaN   \n",
       "...                                                        ...           ...   \n",
       "C5H9 E2_95   114788523.D,114788524.D,114788525.D,114788526....           NaN   \n",
       "     E2_96   114788523.D,114788524.D,114788525.D,114788526....           NaN   \n",
       "     E2_97   114788523.D,114788524.D,114788525.D,114788526....           NaN   \n",
       "     E2_98   114788523.D,114788524.D,114788525.D,114788526....           NaN   \n",
       "     E2_99   114788523.D,114788524.D,114788525.D,114788526....           NaN   \n",
       "\n",
       "            129, 114879985 129, 114896335  \\\n",
       "C5A9 A2_1               WT             WT   \n",
       "     A2_10             NaN            NaN   \n",
       "     A2_100            NaN             WT   \n",
       "     A2_101            NaN            NaN   \n",
       "     A2_102            NaN            NaN   \n",
       "...                    ...            ...   \n",
       "C5H9 E2_95             NaN            NaN   \n",
       "     E2_96              WT            NaN   \n",
       "     E2_97              WT            NaN   \n",
       "     E2_98             NaN            NaN   \n",
       "     E2_99             NaN            NaN   \n",
       "\n",
       "                                                 B6, 114914696  \n",
       "C5A9 A2_1                                                  NaN  \n",
       "     A2_10                                                 NaN  \n",
       "     A2_100                                                NaN  \n",
       "     A2_101  114914747.D,114914748.D,114914749.D,114914750....  \n",
       "     A2_102                                                NaN  \n",
       "...                                                        ...  \n",
       "C5H9 E2_95                                                 NaN  \n",
       "     E2_96                                                 NaN  \n",
       "     E2_97                                                 NaN  \n",
       "     E2_98   114914747.D,114914748.D,114914749.D,114914750....  \n",
       "     E2_99                                                 NaN  \n",
       "\n",
       "[2997 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectionAll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove alleleSites with too much missing data. If a site has >80% missing data it is kicked out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove sites with too many NAs\n",
    "percentage = 0.8 # this removes every alleleSite with > 80% NAs\n",
    "for site,value in (selectionAll.isna().sum(axis=0)/len(selectionAll) < percentage).items():\n",
    "    if value == False:\n",
    "        selectionAll = selectionAll.drop(columns=site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>129, 114682729</th>\n",
       "      <th>B6, 114723869</th>\n",
       "      <th>B6, 114740505</th>\n",
       "      <th>129, 114788469</th>\n",
       "      <th>B6, 114788469</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">C5A9</th>\n",
       "      <th>A2_1</th>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>114740560.D</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2_10</th>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>114740560.D</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2_100</th>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2_101</th>\n",
       "      <td>NaN</td>\n",
       "      <td>WT</td>\n",
       "      <td>114740560.D</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2_102</th>\n",
       "      <td>114682783.D,114682784.D,114682785.D,114682786....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114740560.D</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">C5H9</th>\n",
       "      <th>E2_95</th>\n",
       "      <td>114682778.D,114682779.D,114682780.D,114682781....</td>\n",
       "      <td>114723925.D,114723926.D,114723927.D,114723928....</td>\n",
       "      <td>114740560.D</td>\n",
       "      <td>WT</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E2_96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114740560.D</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E2_97</th>\n",
       "      <td>G.114682786.I,G.114682787.I</td>\n",
       "      <td>114723923.D,114723924.D,114723925.D,114723926....</td>\n",
       "      <td>114740560.D</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E2_98</th>\n",
       "      <td>114682783.D,114682784.D,114682785.D,114682786....</td>\n",
       "      <td>WT</td>\n",
       "      <td>114740560.D</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E2_99</th>\n",
       "      <td>WT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WT</td>\n",
       "      <td>114788523.D,114788524.D,114788525.D,114788526....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2997 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                129, 114682729  \\\n",
       "C5A9 A2_1                                                   WT   \n",
       "     A2_10                                                  WT   \n",
       "     A2_100                                                 WT   \n",
       "     A2_101                                                NaN   \n",
       "     A2_102  114682783.D,114682784.D,114682785.D,114682786....   \n",
       "...                                                        ...   \n",
       "C5H9 E2_95   114682778.D,114682779.D,114682780.D,114682781....   \n",
       "     E2_96                                                 NaN   \n",
       "     E2_97                         G.114682786.I,G.114682787.I   \n",
       "     E2_98   114682783.D,114682784.D,114682785.D,114682786....   \n",
       "     E2_99                                                  WT   \n",
       "\n",
       "                                                 B6, 114723869 B6, 114740505  \\\n",
       "C5A9 A2_1                                                   WT   114740560.D   \n",
       "     A2_10                                                  WT   114740560.D   \n",
       "     A2_100                                                 WT           NaN   \n",
       "     A2_101                                                 WT   114740560.D   \n",
       "     A2_102                                                NaN   114740560.D   \n",
       "...                                                        ...           ...   \n",
       "C5H9 E2_95   114723925.D,114723926.D,114723927.D,114723928....   114740560.D   \n",
       "     E2_96                                                 NaN   114740560.D   \n",
       "     E2_97   114723923.D,114723924.D,114723925.D,114723926....   114740560.D   \n",
       "     E2_98                                                  WT   114740560.D   \n",
       "     E2_99                                                 NaN           NaN   \n",
       "\n",
       "                                                129, 114788469  \\\n",
       "C5A9 A2_1    114788523.D,114788524.D,114788525.D,114788526....   \n",
       "     A2_10   114788523.D,114788524.D,114788525.D,114788526....   \n",
       "     A2_100  114788523.D,114788524.D,114788525.D,114788526....   \n",
       "     A2_101  114788523.D,114788524.D,114788525.D,114788526....   \n",
       "     A2_102  114788523.D,114788524.D,114788525.D,114788526....   \n",
       "...                                                        ...   \n",
       "C5H9 E2_95                                                  WT   \n",
       "     E2_96   114788523.D,114788524.D,114788525.D,114788526....   \n",
       "     E2_97   114788523.D,114788524.D,114788525.D,114788526....   \n",
       "     E2_98   114788523.D,114788524.D,114788525.D,114788526....   \n",
       "     E2_99                                                  WT   \n",
       "\n",
       "                                                 B6, 114788469  \n",
       "C5A9 A2_1    114788523.D,114788524.D,114788525.D,114788526....  \n",
       "     A2_10   114788523.D,114788524.D,114788525.D,114788526....  \n",
       "     A2_100  114788523.D,114788524.D,114788525.D,114788526....  \n",
       "     A2_101  114788523.D,114788524.D,114788525.D,114788526....  \n",
       "     A2_102  114788523.D,114788524.D,114788525.D,114788526....  \n",
       "...                                                        ...  \n",
       "C5H9 E2_95   114788523.D,114788524.D,114788525.D,114788526....  \n",
       "     E2_96   114788523.D,114788524.D,114788525.D,114788526....  \n",
       "     E2_97   114788523.D,114788524.D,114788525.D,114788526....  \n",
       "     E2_98   114788523.D,114788524.D,114788525.D,114788526....  \n",
       "     E2_99   114788523.D,114788524.D,114788525.D,114788526....  \n",
       "\n",
       "[2997 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectionAll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition for graph construction, tree building and tree visualisation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to define the colours based on the full dataset, to make sure that in all trees, the same scars have the same colours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First: define colours based on total set of scars across all gastruloids\n",
    "cmap = plt.get_cmap('hsv')\n",
    "scarColors = {}\n",
    "\n",
    "for alleleSite in selectionAll:\n",
    "    site = alleleSite.split(',')[1]\n",
    "    uniqueScars = selectionAll[alleleSite].unique()\n",
    "    random.seed(3.1415927)\n",
    "    random.shuffle(uniqueScars)    \n",
    "    scarColorsPerSite = { scar: cmap(x) for scar, x in zip(uniqueScars, np.linspace(0,1, len(uniqueScars))) }\n",
    "    scarColorsPerSite.update({'WT':(0,0,0),'nan':'#999999',\n",
    "                              '114788523.D,114788524.D,114788525.D,114788526.D,114788527.D' : '#0109DF' ,\n",
    "                              '114740560.D' : '#0E8700'})\n",
    "    scarColors.update(scarColorsPerSite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTree(gastruloid, df = df, selections = selectionAll, cells_clusters = cells_clusters, \n",
    "             showAllPlots = False, scarColors = scarColors,\n",
    "             transcriptomeColours = 'louvain_colors'):\n",
    "    \n",
    "    ## subset gastruloid\n",
    "    selection = selections.loc[gastruloid]\n",
    "    \n",
    "    ###### First: construct ancestry graph ######\n",
    "    \n",
    "    #construct graph\n",
    "    ancestry_graph = nx.DiGraph()\n",
    "    \n",
    "    for cell_name,row in selection.iterrows():\n",
    "        state_node = {\n",
    "        site:scar for site, scar in row.iteritems() if not 'nonallelic' in site\n",
    "        }\n",
    "        scar_vector = tuple( str(scar) for site, scar in row.iteritems() if not 'nonallelic' in site )\n",
    "\n",
    "        if scar_vector in ancestry_graph: # was already added\n",
    "            ancestry_graph.node[scar_vector]['seen'] += 1\n",
    "            ancestry_graph.node[scar_vector]['associated_cells'].append(cell_name)\n",
    "        else:\n",
    "            ancestry_graph.add_node(\n",
    "                scar_vector,\n",
    "                seen = 1,\n",
    "                associated_cells=[cell_name],\n",
    "                site_data=state_node\n",
    "            )\n",
    "                   \n",
    "    # Filter nodes for seen > param\n",
    "    remove = []\n",
    "    for node in ancestry_graph:\n",
    "        if ancestry_graph.node[node]['seen'] <= 1 and node.count('nan')>1:\n",
    "            remove.append(node)\n",
    "            \n",
    "    ancestry_graph.remove_nodes_from(remove)\n",
    "\n",
    "    scar_vector_order = list(selection.columns)\n",
    "\n",
    "    # Add wildtype node:\n",
    "    state_node = {\n",
    "        site:pre_scar_pattern.get(site,'WT') for site, scar in row.iteritems() if not 'nonallelic' in site\n",
    "    }\n",
    "\n",
    "    root_node = tuple( pre_scar_pattern.get(site,'WT') for site, scar in row.iteritems() if not 'nonallelic' in site )\n",
    "    \n",
    "    # filter out nodes that have different scars than the pre-scars\n",
    "    remove_node = []\n",
    "    for node in ancestry_graph:\n",
    "        for site,scar in pre_scar_pattern.items():\n",
    "            if ancestry_graph.node[node]['site_data'][site] != scar and pd.isna(ancestry_graph.node[node]['site_data'][site]) == False:\n",
    "                remove_node.append(node)\n",
    "\n",
    "    ancestry_graph.remove_nodes_from(remove_node)\n",
    "    scar_vector_order = list(selection.columns)\n",
    "    \n",
    "    ancestry_graph.add_node(\n",
    "        root_node,\n",
    "        seen = 0,\n",
    "        associated_cells=[],\n",
    "        site_data=state_node,\n",
    "        is_root=True   \n",
    "        )\n",
    "\n",
    "    def is_null(value):\n",
    "        if pd.isnull(value):\n",
    "            return True\n",
    "        return value=='nan'\n",
    "\n",
    "    def is_wt(value):\n",
    "        return value=='WT' and not is_null(value)\n",
    "\n",
    "    def is_scar(value):\n",
    "        return not is_null(value) and not is_wt(value)\n",
    "\n",
    "    def scar_distance(from_scar, to_scar, ancestry_graph, root_node ):\n",
    "        # It is no allowed to enter the root node from another state\n",
    "            # Check if we go from a WT site to a scar\n",
    "        if to_scar == root_node:\n",
    "            return None\n",
    "        \n",
    "        #print(f'{from_scar} > {to_scar}')\n",
    "        distance = 0\n",
    "        for site, from_scar_state in ancestry_graph.node[from_scar]['site_data'].items():\n",
    "            to_scar_state = ancestry_graph.node[to_scar]['site_data'][site]\n",
    "        \n",
    "            increment = 0\n",
    "            if  is_wt(from_scar_state) and is_wt(to_scar_state):\n",
    "                 increment = 0 # no cost from WT to WT\n",
    "            \n",
    "            elif  is_scar(from_scar_state) and is_scar(to_scar_state) and to_scar_state==from_scar_state:\n",
    "                increment = 0 # no cost from SCAR to SCAR if they are identical\n",
    "            \n",
    "            elif is_wt(from_scar_state) and is_scar(to_scar_state):\n",
    "                increment = 1\n",
    "            \n",
    "            # Check if we go from scar to WT.. that is impossible\n",
    "            elif is_scar(from_scar_state) and is_wt(to_scar_state):\n",
    "                increment = None\n",
    "\n",
    "            # Check if the from_scar is a subset of the to_scar:\n",
    "            else:\n",
    "                # Allow to go from non-na to na \n",
    "                if  not is_null(from_scar_state)  and is_null(to_scar_state) :\n",
    "                    increment =1\n",
    "                else:\n",
    "                    increment = None\n",
    "                #if set(from_scar_state.split(',') ).issubset(  set(to_scar_state.split(',') )):\n",
    "                #    distance+=1.5\n",
    "            #print(f'\\t{site} {from_scar_state}->{to_scar_state} = {increment}')\n",
    "        \n",
    "            if increment is None:\n",
    "                return None\n",
    "            distance += increment\n",
    "        \n",
    "        return distance    \n",
    "    \n",
    "    for from_scar, to_scar in itertools.product(ancestry_graph.node, repeat=2) :\n",
    "        # Calculate distance between two nodes:\n",
    "        distance = scar_distance(from_scar, to_scar, ancestry_graph, root_node=root_node )\n",
    "        if distance is None:\n",
    "            #print(f\"Not making edge between root_node and {from_scar}\")\n",
    "            pass\n",
    "        else:\n",
    "            ancestry_graph.add_edge(from_scar,to_scar, distance=distance)\n",
    "            ancestry_graph.add_edge(from_scar,to_scar, weight= distance)\n",
    "        \n",
    "    for from_node,to_node in ancestry_graph.edges():\n",
    "        if to_node==root_node:\n",
    "            print(from_node, to_node)\n",
    "    \n",
    "    pos = nx.spring_layout(ancestry_graph)\n",
    "    \n",
    "    if showAllPlots == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        nx.draw_networkx(ancestry_graph, pos)\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    ###### Then: construct spanning_arb ######\n",
    "    \n",
    "    \n",
    "    spanning_arb = nx.algorithms.tree.branchings.Edmonds( ancestry_graph ).find_optimum(\n",
    "        style='arborescence', \n",
    "        kind='min',\n",
    "        default=0,\n",
    "          preserve_attrs=True\n",
    "    )\n",
    "\n",
    "    # Manually copy attributes:\n",
    "    for node in spanning_arb:\n",
    "        spanning_arb.node[node].update( ancestry_graph.node[node] )\n",
    "        \n",
    "    # Now copy all only nan changes into their parent..\n",
    "    changed=True\n",
    "    while changed:\n",
    "        changed=False\n",
    "        for node in spanning_arb:\n",
    "            if nx.degree(spanning_arb, node)==0:\n",
    "                continue\n",
    "            if len( list(spanning_arb.successors(node)) )==0:\n",
    "                # we are inside a leaf:\n",
    "                #comapre ourself to parent:\n",
    "                parent = list(spanning_arb.predecessors(node))[0]\n",
    "                # check if distance is caused by nan\n",
    "                if not any( list( not( (a==b) or  (is_null(a) or is_null(b)) ) for a,b in  zip(parent,node) ) ):\n",
    "                    # we should merge to parent:\n",
    "                    spanning_arb.node[parent]['associated_cells'] += spanning_arb.node[node]['associated_cells']\n",
    "                    spanning_arb.node[parent]['seen'] += spanning_arb.node[node]['seen']\n",
    "                    spanning_arb.remove_node(node)\n",
    "                    changed=True\n",
    "                    break\n",
    "    \n",
    "    pos = nx.spring_layout(spanning_arb)\n",
    "    \n",
    "    #spanning_arb.node[list(spanning_arb)[0]]\n",
    "   \n",
    "    if showAllPlots == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        nx.draw_networkx(spanning_arb, pos)\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    ###### Then: clean up graph ######\n",
    "    \n",
    "    def format_node_name(node):\n",
    "        return '_'.join(node)\n",
    "\n",
    "    clean_graph = nx.DiGraph()\n",
    "    for node in spanning_arb:\n",
    "        sites_modified = {\n",
    "            'AAP'+str(site).replace(', ','X'):str(scar)\n",
    "            for site,scar in ancestry_graph.node[node]['site_data'].items()\n",
    "            if not is_null(scar)    \n",
    "        }\n",
    "        \n",
    "        clean_graph.add_node(format_node_name(node), \n",
    "                             associatedCells ='_'.join( ancestry_graph.node[node]['associated_cells'] ),  \n",
    "                             totalCells = ancestry_graph.node[node]['seen'],\n",
    "                             changes=format_node_name(node).count('.'),\n",
    "                             wildTypes=format_node_name(node).count('WT'),\n",
    "                             nans=format_node_name(node).count('nan'),\n",
    "                             isRoot=ancestry_graph.node[node].get('is_root',False),\n",
    "                                **sites_modified\n",
    "                            )\n",
    "\n",
    "    for a,b in spanning_arb.edges():\n",
    "        clean_graph.add_edge(\n",
    "            format_node_name(a),\n",
    "            format_node_name(b),  \n",
    "            scarDistance=ancestry_graph[a][b]['distance'])\n",
    "\n",
    "    #nx.write_gml(clean_graph,'scar_graph.gml')\n",
    "    \n",
    "\n",
    "    ###### Then: create expanded graph ######\n",
    "    \n",
    "    # Create pseudo timepoint expansion\n",
    "\n",
    "    # detect depth of tree (max len path) + 1\n",
    "    pseudo_timepoint_len = len( nx.algorithms.dag.dag_longest_path(spanning_arb, weight='NONE') ) + 1\n",
    "\n",
    "    expanded_graph = nx.DiGraph()\n",
    "    expanded_graph.add_node( (root_node,0), \n",
    "                            radius=1, first_tp = 0,\n",
    "                            **ancestry_graph.node[root_node] )\n",
    "\n",
    "    for node in spanning_arb:\n",
    "        # the first pseudotimepoint of the node is at the distance to the root \n",
    "        try:\n",
    "            if node == root_node:\n",
    "                first_tp = 0\n",
    "            else:\n",
    "                first_tp = nx.shortest_path_length( spanning_arb, root_node, node )\n",
    "            prev = None\n",
    "            # expand the node to every timepoint until the end of pseudotime:\n",
    "            for tp in range(first_tp,pseudo_timepoint_len):\n",
    "                expanded_graph.add_node( (node,tp), \n",
    "                                        radius=ancestry_graph.node[node]['seen'], first_tp = first_tp,\n",
    "                                        **ancestry_graph.node[node] )\n",
    "                spanning_arb.node[node]['first_tp'] = first_tp\n",
    "                if prev is not None:\n",
    "                    expanded_graph.add_edge( prev, (node,tp) )\n",
    "                prev = (node,tp) \n",
    "        except nx.NetworkXNoPath:\n",
    "            continue\n",
    "    # Now create inter-clone edges:\n",
    "    for from_node, to_node in spanning_arb.edges():\n",
    "        to_tp = spanning_arb.node[to_node]['first_tp']\n",
    "        from_tp = to_tp - 1\n",
    "        expanded_graph.add_edge((from_node,from_tp) , (to_node,to_tp))\n",
    "         \n",
    "    # same layout using matplotlib with no labels\n",
    "    pos = graphviz_layout(expanded_graph, prog='dot')\n",
    "\n",
    "    if showAllPlots == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        nx.draw_networkx(expanded_graph, pos)\n",
    "        plt.show()\n",
    "\n",
    "    expanded_graph[root_node,0]\n",
    "\n",
    "    expanded_graph = nx.algorithms.tree.branchings.Edmonds( expanded_graph ).find_optimum(\n",
    "        style='arborescence', \n",
    "        kind='min',\n",
    "        preserve_attrs=True,\n",
    "        default=0,\n",
    "    )\n",
    "    \n",
    "# Copy attributes because preserve_attrs is not working\n",
    "    for node,tp in expanded_graph:\n",
    "        expanded_graph.node[node,tp]['radius'] = ancestry_graph.node[node]['seen']\n",
    "    \n",
    "    # same layout using matplotlib with no labels\n",
    "    pos = graphviz_layout(expanded_graph, prog='dot')\n",
    "\n",
    "    initial_order = [(state) for state, tp in pd.DataFrame(pos).T.sort_values(0).index]\n",
    "    seen = set()\n",
    "    initial_order = [x for x in initial_order if (x not in seen) and not seen.add(x)]\n",
    "\n",
    "    #expanded_graph.node[list(expanded_graph)[1]]\n",
    " \n",
    "\n",
    "    ###### Create toverboom topology ######\n",
    "    \n",
    "    # Instantiate the lineage graph object\n",
    "    lg = toverboom.lineageGraph.LineageGraph(expanded_graph)\n",
    "\n",
    "    for node in lg.graph:\n",
    "        if len(list(lg.graph.successors(node)))==0:\n",
    "            lg.graph.node[node]['leaf'] = True\n",
    "        else:\n",
    "            lg.graph.node[node]['leaf'] = False\n",
    "\n",
    "    # Create a figure for our plot:\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Find the best layout\n",
    "    toverboom.optimizeLayout.optimize_layout(lg,\n",
    "                                             visualize_progress_ax=ax, \n",
    "                                             visualize_progress_fig=fig,\n",
    "                                             #initial_order=initial_order ,no_optim=True     \n",
    "                                            )\n",
    "    pass\n",
    "\n",
    "\n",
    "    ###### Make dataframe that is used as input for tree visualisation ######\n",
    "    \n",
    "    cellDataDict = collections.defaultdict(dict)\n",
    "    for clone,tp in lg.graph:\n",
    "        if tp==(pseudo_timepoint_len-1):\n",
    "            lg.graph.node[(clone,tp)]['radius'] = len(ancestry_graph.node[clone]['associated_cells'])\n",
    "        \n",
    "            for cell in ancestry_graph.node[clone]['associated_cells']:\n",
    "                cellDataDict[(clone,tp,cell)] = {'tp':tp, 'cluster':clone}\n",
    "    \n",
    "    cellData = pd.DataFrame(cellDataDict).T\n",
    "    \n",
    "    \n",
    "    ###### Couple scar dataframe to transcriptome dataframe ######    \n",
    "    \n",
    "    cellData2 = cellData.copy()\n",
    "    index = cellData2.reset_index()\n",
    "    index['cellname'] = index['level_2']\n",
    "\n",
    "    cellData2 = index.merge(cells_clusters, on = 'cellname')\n",
    "    cellData2 = cellData2.set_index(['level_0','level_1','level_2'])\n",
    "\n",
    "    def scale(coordinates,pc = 10):\n",
    "        start = np.percentile(coordinates,pc) \n",
    "        end = np.percentile(coordinates,100-pc)\n",
    "        return np.interp(coordinates, (start, end), (0.4, 1))\n",
    "\n",
    "    cellData2['x']  = scale(cellData2['umap_V1'].fillna(0))\n",
    "    cellData2['y'] = scale(cellData2['umap_V2'].fillna(0))\n",
    "\n",
    "    \n",
    "###### MAKE TREE #######\n",
    "\n",
    "    cells = list(cellData.index)\n",
    "\n",
    "    cellData2['x']-=1\n",
    "    \n",
    "    cellData2['size']= 15\n",
    "\n",
    "    # Plot the polygons of the tree\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # wavyness controls how wavy the segments of the tree are \n",
    "    wavyness=0.7\n",
    "    # xDistance controls the stretch in the x direction \n",
    "    lg.xDistance= 10\n",
    "    lg.verticalSpacing = 2\n",
    "\n",
    "    lg.setRadiusAttributes(radiusAttribute='radius', \n",
    "                           defaultRadius=1, \n",
    "                           radiusMultiplier=0.2 )\n",
    "\n",
    "    lg.plotEdges(ax, bezier=True,wavyness=wavyness,stepCount=30,plotArgs={'linewidth':0}, offsetCentroid=True)\n",
    "    lg.plotPatches(ax=ax,wavyness=wavyness)\n",
    "\n",
    "    # Remove plot spines:\n",
    "    toverboom.lineageGraph.despine(ax)\n",
    "    # Scale labels to plot size:\n",
    "    toverboom.lineageGraph.format_x_axis_labels(ax)\n",
    "\n",
    "    # Add labels to the clones:\n",
    "\n",
    "\n",
    "    allClones = set([ cluster for cluster,tp in lg.graph ]) - set([0])\n",
    "    bigClones = set([1,4,2,3,5])\n",
    "\n",
    "    #cellData = cellCnvBarcode\n",
    "    #cellData['tp'] = [passage for passage, plate, cell in list(cellData.index)]\n",
    "\n",
    "    # Remove plot spines:\n",
    "    toverboom.lineageGraph.despine(ax)\n",
    "\n",
    "    # Scale labels to plot size:\n",
    "    toverboom.lineageGraph.format_x_axis_labels(ax)\n",
    "\n",
    "    # Add vertical lines to indicate sampled timepoints\n",
    "    lg.plot_xticks(ax, [x for x in cellData2['tp'].unique()])\n",
    "    lg.plot_vertical_lines(ax, cellData2['tp'].unique(), c='k')\n",
    "\n",
    "    lg.plotSingleCells(ax=ax, cellData = cellData2,fig=fig, cellJitter = 4,\n",
    "                       colorAttribute = transcriptomeColours,yOffsetAttribute='y',xOffsetAttribute='x',\n",
    "                       yJitterRatio=2,defaultXOffset = 50,defaultYOffset = 50,\n",
    "                       defaultLinewidth = 0.5)\n",
    "    \n",
    "\n",
    "    ax.set_xlabel('Pseudotime')\n",
    "\n",
    "    x_start = lg.getXCoordinate(pseudo_timepoint_len) - 8\n",
    "    rect_size = 4\n",
    "\n",
    "    #lg.annotateNodes(ax=ax)\n",
    "\n",
    "    maxY = max([y for clone,y in lg.getTrellisCoordinates().items()])\n",
    "    for clone, y in lg.getTrellisCoordinates().items():\n",
    "    \n",
    "        for i,scar in enumerate(clone):\n",
    "            x = x_start + (rect_size*i)\n",
    "            if y ==  maxY:\n",
    "                # show label of scar:\n",
    "                ax.text( x+0.5*rect_size,y+5, scar_vector_order[i], ha='center',va='bottom', rotation=90, size='smaller')\n",
    "            node_height = max(2,lg.getNodeRadius( node=(clone,pseudo_timepoint_len-1) )*2)\n",
    "        \n",
    "            ax.add_patch(\n",
    "                matplotlib.patches.Rectangle((x, y-node_height*0.5), \n",
    "                                             rect_size,node_height,\n",
    "                                             fc=scarColors.get(scar,'r'), label = scar_vector_order[i] + str(': ') + (scar[0:12] + str(' - ') + scar[-11:-1] + scar[-1])\n",
    "                                    \n",
    "                                            ),\n",
    "        \n",
    "            )\n",
    "\n",
    "    ax.legend(ncol = 5, fontsize=5)\n",
    "\n",
    "    def legend_without_duplicate_labels(ax):\n",
    "        newUnique = []\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        unique = [(h, l) for i, (h, l) in enumerate(zip(handles, labels)) if l not in labels[:i]]\n",
    "        for site in scar_vector_order:\n",
    "            for handles,labels in unique:\n",
    "                if site in labels:\n",
    "                    newUnique.append((handles,labels))\n",
    "        ax.legend(*zip(*newUnique), fontsize = 6, loc='center right',bbox_to_anchor=(1.12,0.5))\n",
    "    \n",
    "\n",
    "    legend_without_duplicate_labels(ax)\n",
    "\n",
    "    ax.get_yaxis().set_visible(False) \n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_xlabel('Pseudotime')\n",
    "    ax.set_xlim(0, x_start + (rect_size*(i+5))) \n",
    "    ax.set_ylim(0,maxY+24) \n",
    "\n",
    "    fig.canvas.draw()\n",
    "#\n",
    "#plt.savefig('/Users/m.blotenburg/Desktop/120hAA_C5H11.png', dpi=500)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine which gastruloids are present in the data and run the tree building for each gastruloid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the amount of cells for each gastruloid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'C5A9': 259,\n",
       "         'C5B10': 347,\n",
       "         'C5C6': 319,\n",
       "         'C5F10': 370,\n",
       "         'C5G7': 524,\n",
       "         'C5H11': 486,\n",
       "         'C5H7': 356,\n",
       "         'C5H9': 336})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter([gastruloid for gastruloid, cell in df.index]) #groupby('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeTree('C5A9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeTree('C5B10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "makeTree('C5C6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeTree('C5F10') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "makeTree('C5G7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "makeTree('C5H11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "makeTree('C5H7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "makeTree('C5H9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "makeTree('C5F10', transcriptomeColours='germlayer_colors', showAllPlots = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
